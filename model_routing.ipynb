{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9c56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"/home/bipin/Documents/genai/g25-nov-hindi/python-nov/.env\")\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm1 = ChatOpenAI(model=\"gpt-5-nano\") # Greeting, rewrite, summary, translation\n",
    "llm2=ChatOllama(model=\"granite4:latest\") #Offline / privacy / dev testing\n",
    "llm3 = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\") #Fast multimodal / Google ecosystem\n",
    "llm4=ChatOpenAI(model=\"gpt-5-mini\") # Medium reasoning, Q&A, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c5d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "szubh5pamvg",
   "metadata": {},
   "source": [
    "# Model Routing with if/elif/else \n",
    "\n",
    "In this notebook, we'll learn how to route user queries to different AI models based on various conditions using if/elif/else statements.\n",
    "| Task Type                               | Model               |\n",
    "| --------------------------------------- | ------------------- |\n",
    "| Greeting, rewrite, summary, translation | `gpt-5-nano`        |\n",
    "| Medium reasoning, Q&A, explanation      | `gpt-5-mini`        |\n",
    "| Offline / privacy / dev testing         | `granite4` (Ollama) |\n",
    "| Fast multimodal / Google ecosystem      | `gemini-2.5-flash`  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da030ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_llm = llm1  # cheap router model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053616a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236d4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = \"\"\"\n",
    "You are a model router.\n",
    "Decide the best model for the task.\n",
    "\n",
    "Models:\n",
    "- nano: simple, cheap\n",
    "- mini: reasoning\n",
    "- local: offline/privacy\n",
    "- gemini: fast/multimodal\n",
    "\n",
    "User task: {task}\n",
    "\n",
    "Answer with only one word:\n",
    "nano | mini | local | gemini\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e013b2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mini'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"what does rocket engine. what is reason for heavy fuelling in rocket\"\n",
    "final_prompt=router_prompt.format(\n",
    "    task=query\n",
    ")\n",
    "decision_output = router_llm.invoke(final_prompt)\n",
    "decision=decision_output.content\n",
    "decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28efcfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genrating output through mini\n",
      "Short answers first:\n",
      "- A rocket engine burns (or otherwise accelerates) propellant and ejects high-speed reaction mass (exhaust) out the back. The push from the exhaust produces thrust (Newton‚Äôs third law).\n",
      "- Rockets are ‚Äúheavily fueled‚Äù because getting into orbit or to another destination requires a very large change in velocity (delta‚Äëv). The rocket equation makes the required fuel grow exponentially with delta‚Äëv, so most of a rocket‚Äôs launch mass must be propellant.\n",
      "\n",
      "More detail\n",
      "\n",
      "What a rocket engine does\n",
      "- Converts stored energy (usually chemical) into hot, high‚Äëpressure gas.\n",
      "- The gas is expanded and accelerated through a nozzle so it leaves the vehicle at very high speed. The momentum carried away by the exhaust produces an equal and opposite thrust on the rocket.\n",
      "- Performance is described by specific impulse (Isp) or effective exhaust velocity ve; higher Isp means more thrust per kilogram of propellant.\n",
      "- Key components: combustion chamber, injector, nozzle. Engine parameters that matter: chamber pressure, exhaust velocity (Isp), mass flow rate.\n",
      "\n",
      "Why rockets carry so much fuel\n",
      "- Rockets must carry both payload and the reaction mass (fuel + oxidizer) needed to change velocity. They do not push against air or ground; they push against their own expelled mass.\n",
      "- The Tsiolkovsky rocket equation shows the consequence:\n",
      "  delta‚Äëv = ve * ln(m0 / mf)\n",
      "  where m0 = initial mass (rocket + fuel), mf = final mass (rocket without the used fuel), ve = effective exhaust velocity.\n",
      "- Because delta‚Äëv depends on the natural log of the mass ratio, achieving large delta‚Äëv requires a large initial-to-final mass ratio. In practice this means propellant is the majority of the launch mass.\n",
      "  Example: to reach low Earth orbit (including losses) you need ~9‚Äì10 km/s. With a high‚Äëperformance engine (Isp ‚âà 450 s, ve ‚âà 4.4 km/s) the mass ratio needed is about 8‚Äì9, so ~88‚Äì90% of the vehicle mass is propellant. Lower Isp engines require an even larger fuel fraction.\n",
      "\n",
      "Other practical reasons you see ‚Äúheavy fueling‚Äù\n",
      "- Gravity and atmospheric drag losses: you must overcome gravity during climb, which increases required delta‚Äëv and fuel.\n",
      "- Structural and engine mass: some mass must be nonswappable structure and engines; that reduces payload fraction, forcing more propellant for the same delta‚Äëv.\n",
      "- Staging: to avoid impractical mass ratios, rockets use multiple stages so each stage can have a better mass fraction.\n",
      "- Tanking logistics: cryogenic propellants are often loaded shortly before launch to avoid boil‚Äëoff, so you see big fueling operations prelaunch.\n",
      "\n",
      "In short: a rocket engine makes thrust by ejecting reaction mass at high speed, and rockets need to carry enormous amounts of propellant because the physics of the rocket equation makes the required fuel grow rapidly with the required change in velocity.\n"
     ]
    }
   ],
   "source": [
    "if decision == \"nano\":\n",
    "    print(\"genrating output through nano\")\n",
    "    output =llm1.invoke(query)\n",
    "elif decision == \"mini\":\n",
    "    print(\"genrating output through mini\")\n",
    "    output =llm4.invoke(query)\n",
    "elif decision == \"local\":\n",
    "    print(\"genrating output through local\")\n",
    "    output =llm2.invoke(query)\n",
    "elif decision == \"gemini\":\n",
    "    print(\"genrating output through gemini\")\n",
    "\n",
    "    output =llm3.invoke(query)\n",
    "else:\n",
    "    output =llm4.invoke(query)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a5b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa72900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ldifslhxk3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Route based on query length\n",
    "query = \"What is Python?\"\n",
    "word_count = len(query.split())\n",
    "\n",
    "if word_count < 10:\n",
    "    print(f\"Short query ({word_count} words) ‚Üí Using GPT-4o-mini\")\n",
    "    response = llm1.invoke(query)\n",
    "else:\n",
    "    print(f\"Long query ({word_count} words) ‚Üí Using GPT-4o\")\n",
    "    response = llm4.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yhtmo5cjgxg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Privacy router\n",
    "query = \"How do I store passwords securely?\"\n",
    "\n",
    "# Check if query contains sensitive keywords\n",
    "if \"password\" in query.lower() or \"secret\" in query.lower() or \"private\" in query.lower():\n",
    "    print(\"‚ö†Ô∏è Sensitive data detected ‚Üí Using LOCAL Granite model\")\n",
    "    response = llm2.invoke(query)\n",
    "else:\n",
    "    print(\"‚úÖ Regular query ‚Üí Using Gemini cloud model\")\n",
    "    response = llm3.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ohref1hhki",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3: Topic-based router\n",
    "query = \"Write a Python function to add two numbers\"\n",
    "\n",
    "if \"code\" in query.lower() or \"programming\" in query.lower() or \"python\" in query.lower():\n",
    "    print(\"üíª Programming query ‚Üí Using GPT-4o-mini\")\n",
    "    response = llm1.invoke(query)\n",
    "elif \"math\" in query.lower() or \"calculation\" in query.lower() or \"calculate\" in query.lower():\n",
    "    print(\"üî¢ Math query ‚Üí Using Gemini\")\n",
    "    response = llm3.invoke(query)\n",
    "else:\n",
    "    print(\"‚ùì General query ‚Üí Using Granite\")\n",
    "    response = llm2.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n3ggcjfsx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4: Budget-based router\n",
    "query = \"Explain quantum computing\"\n",
    "budget = \"medium\"  # Try changing to: \"low\", \"high\", \"none\"\n",
    "\n",
    "if budget == \"low\":\n",
    "    print(\"üíµ Low budget ‚Üí Using GPT-4o-mini\")\n",
    "    response = llm1.invoke(query)\n",
    "elif budget == \"medium\":\n",
    "    print(\"üí∞ Medium budget ‚Üí Using Gemini\")\n",
    "    response = llm3.invoke(query)\n",
    "elif budget == \"high\":\n",
    "    print(\"üíé High budget ‚Üí Using GPT-4o Premium\")\n",
    "    response = llm4.invoke(query)\n",
    "else:\n",
    "    print(\"üÜì No budget ‚Üí Using FREE local Granite\")\n",
    "    response = llm2.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nkp9rjdtcme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5: Language-based router\n",
    "query = \"‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∞‡§æ‡§ú‡§ß‡§æ‡§®‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\"  # What is the capital of India?\n",
    "language = \"hindi\"  # Try: \"english\", \"hindi\", \"other\"\n",
    "\n",
    "if language == \"english\":\n",
    "    print(\"üá¨üáß English query ‚Üí Using GPT-4o-mini\")\n",
    "    response = llm1.invoke(query)\n",
    "elif language == \"hindi\":\n",
    "    print(\"üáÆüá≥ Hindi query ‚Üí Using Gemini (multilingual)\")\n",
    "    response = llm3.invoke(query)\n",
    "else:\n",
    "    print(\"üåè Other language ‚Üí Using Granite\")\n",
    "    response = llm2.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4sg8lfgcma4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 6: Urgency-based router\n",
    "query = \"Debug this production error immediately!\"\n",
    "urgency = \"urgent\"  # Try: \"urgent\", \"important\", \"normal\"\n",
    "\n",
    "if urgency == \"urgent\":\n",
    "    print(\"üö® URGENT ‚Üí Using FASTEST GPT-4o-mini\")\n",
    "    response = llm1.invoke(query)\n",
    "elif urgency == \"important\":\n",
    "    print(\"‚≠ê Important ‚Üí Using BEST GPT-4o\")\n",
    "    response = llm4.invoke(query)\n",
    "else:\n",
    "    print(\"üòå Normal ‚Üí Using local Granite\")\n",
    "    response = llm2.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abo8j2ral1r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge Problem 7: Combined conditions\n",
    "query = \"Please explain how neural networks work in detail\"\n",
    "word_count = len(query.split())\n",
    "\n",
    "if \"explain\" in query.lower() and word_count > 5:\n",
    "    print(\"üìñ Detailed explanation needed ‚Üí Using GPT-4o Premium\")\n",
    "    response = llm4.invoke(query)\n",
    "elif \"summarize\" in query.lower():\n",
    "    print(\"üìù Quick summary ‚Üí Using GPT-4o-mini\")\n",
    "    response = llm1.invoke(query)\n",
    "else:\n",
    "    print(\"ü§ñ Default query ‚Üí Using Gemini\")\n",
    "    response = llm3.invoke(query)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35boj9jo55x",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your practice space - Try creating your own router!\n",
    "query = \"Write your query here\"\n",
    "budget = \"medium\"\n",
    "language = \"english\"\n",
    "\n",
    "# Write your if/elif/else code here:\n",
    "# Hint: You can combine multiple conditions using 'and' or 'or'\n",
    "\n",
    "if budget == \"high\":\n",
    "    response = llm4.invoke(query)\n",
    "    print(\"Using premium model\")\n",
    "elif \"code\" in query.lower():\n",
    "    response = llm1.invoke(query)\n",
    "    print(\"Using coding model\")\n",
    "else:\n",
    "    response = llm3.invoke(query)\n",
    "    print(\"Using default model\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fz9sd63lrgf",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise: Build Your Own Router!\n",
    "\n",
    "**Your Challenge:** Create a router that combines ANY of the above conditions:\n",
    "- Query length\n",
    "- Privacy keywords\n",
    "- Topic (code/math/general)\n",
    "- Budget\n",
    "- Language\n",
    "- Urgency\n",
    "\n",
    "Try modifying the variables and see which model gets selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z35tqzc0c2p",
   "metadata": {},
   "source": [
    "## Challenge Problem 7: Smart Combined Router üß†\n",
    "\n",
    "**Scenario:** Combine multiple conditions!\n",
    "- If query contains \"explain\" AND word_count > 5 ‚Üí Use llm4 (detailed explanations)\n",
    "- Elif query contains \"summarize\" ‚Üí Use llm1 (quick summaries)\n",
    "- Else ‚Üí Use llm3 (default)\n",
    "\n",
    "**Your Task:** Use nested if conditions or logical operators (and/or)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vxmnbq2xcp",
   "metadata": {},
   "source": [
    "## Problem 6: Urgency Router ‚ö°\n",
    "\n",
    "**Scenario:** Route based on urgency level\n",
    "- If urgency is \"urgent\" ‚Üí Use llm1 (fastest)\n",
    "- Elif urgency is \"important\" ‚Üí Use llm4 (best quality)\n",
    "- Else ‚Üí Use llm2 (local, no rush)\n",
    "\n",
    "**Your Task:** Route by urgency!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xt71twvs5q",
   "metadata": {},
   "source": [
    "## Problem 5: Language Router üåç\n",
    "\n",
    "**Scenario:** Route based on language preference\n",
    "- If language is \"english\" ‚Üí Use llm1 (GPT-4o-mini)\n",
    "- Elif language is \"hindi\" ‚Üí Use llm3 (Gemini - good for multilingual)\n",
    "- Else ‚Üí Use llm2 (Granite)\n",
    "\n",
    "**Your Task:** Route queries by language!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cm3pjbx57f",
   "metadata": {},
   "source": [
    "## Problem 4: Budget-Based Router üí∞\n",
    "\n",
    "**Scenario:** Route based on cost budget\n",
    "- If budget is \"low\" ‚Üí Use llm1 (cheap & fast)\n",
    "- Elif budget is \"medium\" ‚Üí Use llm3 (balanced)\n",
    "- Elif budget is \"high\" ‚Üí Use llm4 (premium)\n",
    "- Else ‚Üí Use llm2 (free local model)\n",
    "\n",
    "**Your Task:** Practice if/elif/else!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m0kgokkvt7i",
   "metadata": {},
   "source": [
    "## Problem 3: Topic-Based Router üìö\n",
    "\n",
    "**Scenario:** Route based on query topic (using if/elif/else)\n",
    "- If query is about \"code\" or \"programming\" ‚Üí Use llm1 (GPT-4o-mini)\n",
    "- Elif query is about \"math\" or \"calculation\" ‚Üí Use llm3 (Gemini)\n",
    "- Else ‚Üí Use llm2 (Granite for general questions)\n",
    "\n",
    "**Your Task:** Write if/elif/else to route!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uzeredmqiqo",
   "metadata": {},
   "source": [
    "## Problem 2: Privacy-Sensitive Data Router üîí\n",
    "\n",
    "**Scenario:** Route based on data sensitivity\n",
    "- If query contains \"password\", \"secret\", \"private\" ‚Üí Use local model (llm2) for privacy\n",
    "- Otherwise ‚Üí Use cloud model (llm3)\n",
    "\n",
    "**Your Task:** Complete the if/else!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ravv7n2i21g",
   "metadata": {},
   "source": [
    "## Problem 1: Simple Query Length Router üìè\n",
    "\n",
    "**Scenario:** Route queries based on their length\n",
    "- Short queries (< 10 words) ‚Üí Use fast model (llm1)\n",
    "- Long queries (>= 10 words) ‚Üí Use powerful model (llm4)\n",
    "\n",
    "**Your Task:** Write if/else to route the query!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-nov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
